{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c8141ca-4c44-46d0-92a1-3b6fe618caf2",
   "metadata": {},
   "source": [
    "# Data Science Blog post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a78cb2-b718-4c61-aac1-ab53e13e18ae",
   "metadata": {},
   "source": [
    "Au programme :\n",
    "- étude sur plusieurs années\n",
    "- Quel sont les langages les plus populaire chaque année.\n",
    "- Quels autres changement peuvent être observés chaque année.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c5360b-d3fc-468a-ac59-7d3fd384f5b5",
   "metadata": {},
   "source": [
    "charger les données depuis 2017 \n",
    "\n",
    "on aura donc 2017'2018,2019,2020,2021,2022,2023,2024\n",
    "\n",
    "Donc 8 années à analyser sur un format standardisé.\n",
    "\n",
    "Ce qui permet d'analyser des tendances récentes.\n",
    "\n",
    "- On s'intéressera à la place de l'IA et de stackOverflow dans les entreprises (2questions)\n",
    "- Des langages les plus utilisé au cours du temps (1 question)\n",
    "- De l'évolution des profils utilisant StackOverflow (1 à 2 questions)\n",
    "\n",
    "On a donc 4 à 5 questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a7c1438-8b85-4bc9-9d36-f19531de7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d1627b-e690-4731-9f1c-d72d9899ed75",
   "metadata": {},
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "\n",
    "# Chemin vers le dossier contenant les fichiers ZIP\n",
    "dossier_avec_zips = 'Stack-overflow-developper-survey'\n",
    "\n",
    "# Parcourir tous les fichiers dans le dossier\n",
    "for fichier in os.listdir(dossier_avec_zips):\n",
    "    # Vérifier si le fichier est un fichier ZIP\n",
    "    if fichier.endswith('.zip'):\n",
    "        # Chemin complet du fichier ZIP\n",
    "        chemin_zip = os.path.join(dossier_avec_zips, fichier)\n",
    "        \n",
    "        # Créer un dossier pour ce fichier ZIP\n",
    "        nom_dossier = os.path.splitext(fichier)[0]  # Nom du fichier sans extension .zip\n",
    "        dossier_sortie = os.path.join(dossier_avec_zips, nom_dossier)\n",
    "        \n",
    "        # Si le dossier n'existe pas, le créer\n",
    "        if not os.path.exists(dossier_sortie):\n",
    "            os.makedirs(dossier_sortie)\n",
    "        \n",
    "        # Extraire les fichiers dans le dossier nommé\n",
    "        with zipfile.ZipFile(chemin_zip, 'r') as zip_ref:\n",
    "            zip_ref.extractall(dossier_sortie)\n",
    "        \n",
    "        print(f'Fichier {fichier} extrait dans {dossier_sortie}')\n",
    "\n",
    "print(\"Extraction terminée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3f0e16e-325c-4b44-86de-30f33f99339f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame créé pour stack-overflow-developer-survey-2017 avec le nom survey_results_public_2017\n",
      "DataFrame créé pour stack-overflow-developer-survey-2017 avec le nom survey_results_schema_2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_20060\\3179945136.py:18: DtypeWarning: Columns (8,12,13,14,15,16,50,51,52,53,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(chemin_fichier)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame créé pour stack-overflow-developer-survey-2018 avec le nom survey_results_public_2018\n",
      "DataFrame créé pour stack-overflow-developer-survey-2018 avec le nom survey_results_schema_2018\n",
      "DataFrame créé pour stack-overflow-developer-survey-2019 avec le nom survey_results_public_2019\n",
      "DataFrame créé pour stack-overflow-developer-survey-2019 avec le nom survey_results_schema_2019\n",
      "DataFrame créé pour stack-overflow-developer-survey-2020 avec le nom survey_results_public_2020\n",
      "DataFrame créé pour stack-overflow-developer-survey-2020 avec le nom survey_results_schema_2020\n",
      "DataFrame créé pour stack-overflow-developer-survey-2021 avec le nom survey_results_public_2021\n",
      "DataFrame créé pour stack-overflow-developer-survey-2021 avec le nom survey_results_schema_2021\n",
      "DataFrame créé pour stack-overflow-developer-survey-2022 avec le nom survey_results_public_2022\n",
      "DataFrame créé pour stack-overflow-developer-survey-2022 avec le nom survey_results_schema_2022\n",
      "DataFrame créé pour stack-overflow-developer-survey-2023 avec le nom survey_results_public_2023\n",
      "DataFrame créé pour stack-overflow-developer-survey-2023 avec le nom survey_results_schema_2023\n",
      "DataFrame créé pour stack-overflow-developer-survey-2024 avec le nom survey_results_public_2024\n",
      "DataFrame créé pour stack-overflow-developer-survey-2024 avec le nom survey_results_schema_2024\n",
      "Importation et traitement des fichiers CSV terminés.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chemin vers le répertoire principal contenant les dossiers\n",
    "chemin_principal = 'Stack-overflow-developper-survey'\n",
    "\n",
    "# Parcourir tous les dossiers dans le répertoire principal\n",
    "for dossier in os.listdir(chemin_principal):\n",
    "    # Vérifier si le nom du dossier contient une année entre 2017 et 2024\n",
    "    try:\n",
    "        annee = int(dossier[-4:])  # Assumer que l'année est les 4 derniers caractères\n",
    "        if 2017 <= annee <= 2024:\n",
    "            chemin_dossier = os.path.join(chemin_principal, dossier)\n",
    "            # Assumer que 'survey_results_public.csv' est dans chaque dossier\n",
    "            chemin_fichier = os.path.join(chemin_dossier, 'survey_results_public.csv')\n",
    "            chemin_fichier_schema = os.path.join(chemin_dossier, 'survey_results_schema.csv')\n",
    "            \n",
    "            # Lire le CSV dans un DataFrame\n",
    "            df = pd.read_csv(chemin_fichier)\n",
    "            df_2 = pd.read_csv(chemin_fichier_schema)\n",
    "            \n",
    "            # Nom du DataFrame composé du nom du dossier et de l'année\n",
    "            nom_dataframe = f'survey_results_public_{annee}'\n",
    "            nom_dataframe_schema = f'survey_results_schema_{annee}'\n",
    "            \n",
    "            # Ajouter la colonne 'Year'\n",
    "            df['Year'] = annee\n",
    "\n",
    "            \n",
    "            # Assigner le DataFrame à une variable avec le nom dynamique\n",
    "            globals()[nom_dataframe] = df\n",
    "            globals()[nom_dataframe_schema] = df_2\n",
    "            \n",
    "            print(f'DataFrame créé pour {dossier} avec le nom {nom_dataframe}')\n",
    "            print(f'DataFrame créé pour {dossier} avec le nom {nom_dataframe_schema}')\n",
    "    except ValueError:\n",
    "        # Si le nom du dossier ne se termine pas par une année valide, on passe à l'itération suivante\n",
    "        continue\n",
    "\n",
    "print(\"Importation et traitement des fichiers CSV terminés.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74cd0aae-420d-47a5-b2e4-e2e74d6077e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>QuestionText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Respondent</td>\n",
       "      <td>Randomized respondent ID number (not in order ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hobby</td>\n",
       "      <td>Do you code as a hobby?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OpenSource</td>\n",
       "      <td>Do you contribute to open source projects?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Country</td>\n",
       "      <td>In which country do you currently reside?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Student</td>\n",
       "      <td>Are you currently enrolled in a formal, degree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Age</td>\n",
       "      <td>What is your age? If you prefer not to answer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Dependents</td>\n",
       "      <td>Do you have any children or other dependents t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>MilitaryUS</td>\n",
       "      <td>Are you currently serving or have you ever ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>SurveyTooLong</td>\n",
       "      <td>How do you feel about the length of the survey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>SurveyEasy</td>\n",
       "      <td>How easy or difficult was this survey to compl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Column                                       QuestionText\n",
       "0       Respondent  Randomized respondent ID number (not in order ...\n",
       "1            Hobby                            Do you code as a hobby?\n",
       "2       OpenSource         Do you contribute to open source projects?\n",
       "3          Country          In which country do you currently reside?\n",
       "4          Student  Are you currently enrolled in a formal, degree...\n",
       "..             ...                                                ...\n",
       "124            Age  What is your age? If you prefer not to answer,...\n",
       "125     Dependents  Do you have any children or other dependents t...\n",
       "126     MilitaryUS  Are you currently serving or have you ever ser...\n",
       "127  SurveyTooLong  How do you feel about the length of the survey...\n",
       "128     SurveyEasy  How easy or difficult was this survey to compl...\n",
       "\n",
       "[129 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_results_schema_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3539832f-bc0a-4b05-805d-5b7854c6f71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noms des DataFrames actuellement chargés dans la session :\n",
      "- df\n",
      "- stack-overflow-developer-survey-2017__2017\n",
      "- stack-overflow-developer-survey-2018__2018\n",
      "- stack-overflow-developer-survey-2019__2019\n",
      "- stack-overflow-developer-survey-2020__2020\n",
      "- stack-overflow-developer-survey-2021__2021\n",
      "- stack-overflow-developer-survey-2022__2022\n",
      "- stack-overflow-developer-survey-2023__2023\n",
      "- stack-overflow-developer-survey-2024__2024\n",
      "- survey_results_public_2017\n",
      "- survey_results_public_2018\n",
      "- survey_results_public_2019\n",
      "- survey_results_public_2020\n",
      "- survey_results_public_2021\n",
      "- survey_results_public_2022\n",
      "- survey_results_public_2023\n",
      "- survey_results_public_2024\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour lister les noms des DataFrames dans la session actuelle\n",
    "def list_dataframe_names():\n",
    "    return [name for name, value in globals().items() if isinstance(value, pd.DataFrame)]\n",
    "\n",
    "# Affichage des noms des DataFrames trouvés\n",
    "dataframes_in_session = list_dataframe_names()\n",
    "if dataframes_in_session:\n",
    "    print(\"Noms des DataFrames actuellement chargés dans la session :\")\n",
    "    for name in dataframes_in_session:\n",
    "        print(f\"- {name}\")\n",
    "else:\n",
    "    print(\"Aucun DataFrame n'est chargé dans la session actuelle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6188357-a0ac-4ced-9063-bd976bc60342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feb87dd0-e4b7-4241-8a45-9b8296e8ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données (assurez-vous que le chemin est correct)\n",
    "#df = pd.read_csv('chemin/vers/votre/fichier.csv')\n",
    "df = survey_results_public_2018.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c496080-1ea8-4c7f-b200-6162cebe39f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98855, 130)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abbf70cb-4b22-41f4-bf29-7d65a57b4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les premières lignes du DataFrame\n",
    "#print(\"Premières lignes du DataFrame:\")\n",
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b4f7661-7f84-4b1c-b089-f6db15aa3741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Informations sur le DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 98855 entries, 0 to 98854\n",
      "Columns: 130 entries, Respondent to Year\n",
      "dtypes: float64(41), int64(2), object(87)\n",
      "memory usage: 98.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Informations sur le DataFrame\n",
    "#print(\"\\nInformations sur le DataFrame:\")\n",
    "#print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8244ff9e-468b-4fb8-a080-f15b7942cbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistiques descriptives:\n",
      "          Respondent    AssessJob1    AssessJob2    AssessJob3    AssessJob4  \\\n",
      "count   98855.000000  66985.000000  66985.000000  66985.000000  66985.000000   \n",
      "mean    50822.971635      6.397089      6.673524      5.906875      4.065791   \n",
      "std     29321.650410      2.788428      2.531202      2.642734      2.541196   \n",
      "min         1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "25%     25443.500000      4.000000      5.000000      4.000000      2.000000   \n",
      "50%     50823.000000      7.000000      7.000000      6.000000      4.000000   \n",
      "75%     76219.500000      9.000000      9.000000      8.000000      6.000000   \n",
      "max    101592.000000     10.000000     10.000000     10.000000     10.000000   \n",
      "\n",
      "         AssessJob5    AssessJob6    AssessJob7    AssessJob8    AssessJob9  \\\n",
      "count  66985.000000  66985.000000  66985.000000  66985.000000  66985.000000   \n",
      "mean       3.953243      4.407196      5.673181      4.225200      7.640009   \n",
      "std        2.520499      2.502069      2.923998      2.507411      2.407457   \n",
      "min        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "25%        2.000000      2.000000      3.000000      2.000000      6.000000   \n",
      "50%        3.000000      4.000000      6.000000      4.000000      8.000000   \n",
      "75%        6.000000      6.000000      8.000000      6.000000     10.000000   \n",
      "max       10.000000     10.000000     10.000000     10.000000     10.000000   \n",
      "\n",
      "       ...  JobEmailPriorities7  ConvertedSalary  AdsPriorities1  \\\n",
      "count  ...         46213.000000     4.770200e+04    60479.000000   \n",
      "mean   ...             4.836388     9.578086e+04        2.726880   \n",
      "std    ...             1.659844     2.023482e+05        1.881078   \n",
      "min    ...             1.000000     0.000000e+00        1.000000   \n",
      "25%    ...             4.000000     2.384400e+04        1.000000   \n",
      "50%    ...             5.000000     5.507500e+04        2.000000   \n",
      "75%    ...             6.000000     9.300000e+04        4.000000   \n",
      "max    ...             7.000000     2.000000e+06        7.000000   \n",
      "\n",
      "       AdsPriorities2  AdsPriorities3  AdsPriorities4  AdsPriorities5  \\\n",
      "count    60479.000000    60479.000000    60479.000000    60479.000000   \n",
      "mean         3.805784        3.340945        3.782470        4.383604   \n",
      "std          1.821323        1.673485        1.844864        1.931746   \n",
      "min          1.000000        1.000000        1.000000        1.000000   \n",
      "25%          2.000000        2.000000        2.000000        3.000000   \n",
      "50%          4.000000        3.000000        4.000000        5.000000   \n",
      "75%          5.000000        5.000000        5.000000        6.000000   \n",
      "max          7.000000        7.000000        7.000000        7.000000   \n",
      "\n",
      "       AdsPriorities6  AdsPriorities7     Year  \n",
      "count    60479.000000    60479.000000  98855.0  \n",
      "mean         5.138809        4.821459   2018.0  \n",
      "std          1.853249        1.874895      0.0  \n",
      "min          1.000000        1.000000   2018.0  \n",
      "25%          4.000000        3.000000   2018.0  \n",
      "50%          6.000000        5.000000   2018.0  \n",
      "75%          7.000000        7.000000   2018.0  \n",
      "max          7.000000        7.000000   2018.0  \n",
      "\n",
      "[8 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "# Statistiques descriptives\n",
    "#print(\"\\nStatistiques descriptives:\")\n",
    "#print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1853008e-f3c9-46cb-8984-f6b8e05715a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valeurs manquantes par colonne:\n",
      "Respondent           0\n",
      "Hobby                0\n",
      "OpenSource           0\n",
      "Country            412\n",
      "Student           3954\n",
      "                 ...  \n",
      "Dependents       36259\n",
      "MilitaryUS       83074\n",
      "SurveyTooLong    32914\n",
      "SurveyEasy       32976\n",
      "Year                 0\n",
      "Length: 130, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Vérification des valeurs manquantes\n",
    "print(\"\\nValeurs manquantes par colonne:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54856ecc-8585-4b91-9212-b44cb86fdb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Remplacement des valeurs manquantes (selon le type de la colonne)\\nfor column in df.columns:\\n    if df[column].dtype == \\'object\\':\\n        df[column].fillna(df[column].mode()[0], inplace=True)  # Mode pour les catégoriques\\n    else:\\n        df[column].fillna(df[column].median(), inplace=True)  # Médiane pour les numériques\\n\\n# Distribution des variables numériques\\nnumeric_columns = df.select_dtypes(include=[np.number]).columns\\nfor column in numeric_columns:\\n    plt.figure(figsize=(10, 4))\\n    sns.histplot(df[column], kde=True)\\n    plt.title(f\\'Distribution de {column}\\')\\n    plt.show()\\n\\n# Distribution des variables catégorielles\\ncategorical_columns = df.select_dtypes(include=[\\'object\\']).columns\\nfor column in categorical_columns:\\n    plt.figure(figsize=(10, 4))\\n    sns.countplot(x=df[column], order=df[column].value_counts().index)\\n    plt.title(f\\'Distribution de {column}\\')\\n    plt.xticks(rotation=90)\\n    plt.show()\\n\\n# Corrélation entre variables numériques\\ncorrelation_matrix = df[numeric_columns].corr()\\nplt.figure(figsize=(12, 10))\\nsns.heatmap(correlation_matrix, annot=True, cmap=\\'coolwarm\\', linewidths=0.5)\\nplt.title(\\'Matrice de corrélation des variables numériques\\')\\nplt.show()\\n\\n# Relation entre une variable numérique et une catégorielle (exemple)\\nif len(numeric_columns) > 0 and len(categorical_columns) > 0:\\n    example_num = numeric_columns[0]\\n    example_cat = categorical_columns[0]\\n    plt.figure(figsize=(10, 6))\\n    sns.boxplot(x=example_cat, y=example_num, data=df)\\n    plt.title(f\\'Relation entre {example_cat} et {example_num}\\')\\n    plt.show()\\n\\n# Outliers - Utilisation de la méthode IQR pour les variables numériques\\nfor column in numeric_columns:\\n    Q1 = df[column].quantile(0.25)\\n    Q3 = df[column].quantile(0.75)\\n    IQR = Q3 - Q1\\n    lower_bound = Q1 - 1.5 * IQR\\n    upper_bound = Q3 + 1.5 * IQR\\n    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)][column]\\n    print(f\"\\nOutliers pour {column}:\")\\n    print(outliers)\\n\\nprint(\"Exploration des données terminée.\")\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "# Remplacement des valeurs manquantes (selon le type de la colonne)\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        df[column].fillna(df[column].mode()[0], inplace=True)  # Mode pour les catégoriques\n",
    "    else:\n",
    "        df[column].fillna(df[column].median(), inplace=True)  # Médiane pour les numériques\n",
    "\n",
    "# Distribution des variables numériques\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "for column in numeric_columns:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.histplot(df[column], kde=True)\n",
    "    plt.title(f'Distribution de {column}')\n",
    "    plt.show()\n",
    "\n",
    "# Distribution des variables catégorielles\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "for column in categorical_columns:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.countplot(x=df[column], order=df[column].value_counts().index)\n",
    "    plt.title(f'Distribution de {column}')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "# Corrélation entre variables numériques\n",
    "correlation_matrix = df[numeric_columns].corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Matrice de corrélation des variables numériques')\n",
    "plt.show()\n",
    "\n",
    "# Relation entre une variable numérique et une catégorielle (exemple)\n",
    "if len(numeric_columns) > 0 and len(categorical_columns) > 0:\n",
    "    example_num = numeric_columns[0]\n",
    "    example_cat = categorical_columns[0]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=example_cat, y=example_num, data=df)\n",
    "    plt.title(f'Relation entre {example_cat} et {example_num}')\n",
    "    plt.show()\n",
    "\n",
    "# Outliers - Utilisation de la méthode IQR pour les variables numériques\n",
    "for column in numeric_columns:\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)][column]\n",
    "    print(f\"\\nOutliers pour {column}:\")\n",
    "    print(outliers)\n",
    "\n",
    "print(\"Exploration des données terminée.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4faeaa-6ad4-4fe2-9d5c-35560079804b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a712ac25-93c5-4bad-b8d0-7fc5b510c1db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac16b484-a9f4-461e-b3ea-4a92dc80f0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca906d0e-7ab6-4499-b9da-ef820d1f8c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63fa512-0b91-459d-9f16-d2f4413eed7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e26c1cc-57be-4f94-9216-cb57fbfaa9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17f9af35-2301-413d-a5c7-f9700865c097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier 2011 Stack Overflow Survey Results.csv chargé avec encodage latin1 après échec de détection.\n",
      "Fichier 2012 Stack Overflow Survey Results.csv chargé avec encodage latin1 après échec de détection.\n",
      "Fichier 2013 Stack Overflow Survey Responses.csv chargé avec encodage latin1 après échec de détection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_16212\\112480368.py:35: DtypeWarning: Columns (46,48,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  globals()[df_name] = pd.read_csv(file_path, encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier 2014 Stack Overflow Survey Responses.csv chargé avec encodage latin1 après échec de détection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marc\\AppData\\Local\\Temp\\ipykernel_16212\\112480368.py:28: DtypeWarning: Columns (5,108,121,196,197,198) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  globals()[df_name] = pd.read_csv(file_path, encoding=encoding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier 2015 Stack Overflow Developer Survey Responses.csv chargé dans le DataFrame 2015 Stack Overflow Developer Survey Responses avec l'encodage utf-8.\n",
      "Fichier survey_results_public.csv chargé dans le DataFrame survey_results_public avec l'encodage utf-8.\n",
      "Fichier survey_results_schema.csv chargé dans le DataFrame survey_results_schema avec l'encodage utf-8.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import chardet\n",
    "\n",
    "# Chemin vers le dossier contenant les fichiers CSV\n",
    "csv_dir = 'Data'\n",
    "\n",
    "# Obtenir la liste des fichiers CSV dans le dossier\n",
    "csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
    "\n",
    "# Fonction pour détecter l'encodage d'un fichier\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        result = chardet.detect(file.read(100000))\n",
    "    return result['encoding']\n",
    "\n",
    "# Charger chaque fichier CSV dans un DataFrame en gérant les problèmes d'encodage\n",
    "for csv_file in csv_files:\n",
    "    # Construire le chemin complet du fichier\n",
    "    file_path = os.path.join(csv_dir, csv_file)\n",
    "    \n",
    "    try:\n",
    "        # Détecter l'encodage du fichier\n",
    "        encoding = detect_encoding(file_path)\n",
    "        \n",
    "        # Charger le CSV dans un DataFrame avec l'encodage détecté\n",
    "        df_name = csv_file.split('.')[0]  # Nom du DataFrame sans l'extension '.csv'\n",
    "        globals()[df_name] = pd.read_csv(file_path, encoding=encoding)\n",
    "        \n",
    "        # Afficher un message de confirmation\n",
    "        print(f'Fichier {csv_file} chargé dans le DataFrame {df_name} avec l\\'encodage {encoding}.')\n",
    "    except UnicodeDecodeError:\n",
    "        # Si l'encodage détecté ne fonctionne pas, essayer avec 'latin1' ou 'utf-8' avec gestion des erreurs\n",
    "        try:\n",
    "            globals()[df_name] = pd.read_csv(file_path, encoding='latin1')\n",
    "            print(f'Fichier {csv_file} chargé avec encodage latin1 après échec de détection.')\n",
    "        except:\n",
    "            globals()[df_name] = pd.read_csv(file_path, encoding='utf-8', errors='replace')\n",
    "            print(f'Fichier {csv_file} chargé avec encodage utf-8 (erreurs remplacées) après échec de détection et latin1.')\n",
    "\n",
    "# Exemple d'utilisation : pour vérifier que les DataFrames ont été chargés\n",
    "# Note : Ceci est juste un exemple, adaptez selon les DataFrames que vous avez réellement chargés\n",
    "# print(nom_du_dataframe.head())  # Remplacez 'nom_du_dataframe' par le nom réel d'un de vos DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e582a783-f9e6-408c-a3cf-8987d50329cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noms des DataFrames actuellement chargés dans la session :\n",
      "- 2011 Stack Overflow Survey Results\n",
      "- 2012 Stack Overflow Survey Results\n",
      "- 2013 Stack Overflow Survey Responses\n",
      "- 2014 Stack Overflow Survey Responses\n",
      "- 2015 Stack Overflow Developer Survey Responses\n",
      "- survey_results_public\n",
      "- survey_results_schema\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Fonction pour lister les noms des DataFrames dans la session actuelle\n",
    "def list_dataframe_names():\n",
    "    return [name for name, value in globals().items() if isinstance(value, pd.DataFrame)]\n",
    "\n",
    "# Affichage des noms des DataFrames trouvés\n",
    "dataframes_in_session = list_dataframe_names()\n",
    "if dataframes_in_session:\n",
    "    print(\"Noms des DataFrames actuellement chargés dans la session :\")\n",
    "    for name in dataframes_in_session:\n",
    "        print(f\"- {name}\")\n",
    "else:\n",
    "    print(\"Aucun DataFrame n'est chargé dans la session actuelle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd926d5a-8475-4a8b-bb78-04383ffed1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noms des DataFrames après standardisation :\n",
      "- 2011_stack_overflow_survey_results\n",
      "- 2012_stack_overflow_survey_results\n",
      "- 2013_stack_overflow_survey_responses\n",
      "- 2014_stack_overflow_survey_responses\n",
      "- 2015_stack_overflow_developer_survey_responses\n",
      "- survey_results_public\n",
      "- survey_results_schema\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def list_and_standardize_dataframe_names():\n",
    "    # Liste des DataFrames dans la session\n",
    "    dataframes = {name: value for name, value in globals().items() if isinstance(value, pd.DataFrame)}\n",
    "    \n",
    "    # Standardiser les noms des DataFrames\n",
    "    standardized_names = {}\n",
    "    for old_name, df in dataframes.items():\n",
    "        new_name = old_name.lower().replace(' ', '_')\n",
    "        \n",
    "        # Si le nouveau nom existe déjà, ajouter un suffixe numérique\n",
    "        counter = 1\n",
    "        while new_name in standardized_names:\n",
    "            new_name = f\"{new_name}_{counter}\"\n",
    "            counter += 1\n",
    "        \n",
    "        standardized_names[new_name] = df\n",
    "        globals()[new_name] = df  # Mettre à jour le nom dans la session\n",
    "        \n",
    "        if old_name != new_name:\n",
    "            del globals()[old_name]  # Supprimer l'ancien nom si différent\n",
    "\n",
    "    return list(standardized_names.keys())\n",
    "\n",
    "# Afficher les noms des DataFrames après standardisation\n",
    "standardized_df_names = list_and_standardize_dataframe_names()\n",
    "if standardized_df_names:\n",
    "    print(\"Noms des DataFrames après standardisation :\")\n",
    "    for name in standardized_df_names:\n",
    "        print(f\"- {name}\")\n",
    "else:\n",
    "    print(\"Aucun DataFrame n'est chargé dans la session actuelle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2af0b3e1-4a93-4820-88a9-24314dbb57b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Décompression terminée.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68cf30b-dee5-43bc-b8d3-2909a04cd482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
